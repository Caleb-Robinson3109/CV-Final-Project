\section{Analysis}
\label{sec:analysis}

The R squared scores, which indicate the predicted values' similarity to the corresponding actual values, are generally all very low, to a concerning extent. It's surprising that the visual meshes of the combined model's output bear even any vague resemblance to the original KITRO output, given that the R squared scores are so low. It wouldn't be too surprising if they were somewhat low, given the high number of features that need to be predicted, the amount of potential noise that is in the set of independent (X) data, how drastically the parameters can change while staying within reason for a 3D human mesh, and how changes in one joint tend to propagate to nearby joints, leading to complex changes in the data. After running multiple trials with different feature column configurations, though, it is concerning that the R squared scores are low to the point of being not very useful as metrics, even when they differ between trials.

The R squared scores of the trials where the refined vertices features were excluded from the dataset are noticeably higher than the scores of the trials where they were included. Although that may be a coincidence caused by the scores already being incredibly low, it supports the idea that they hinder Random Forest regression from getting accurate results, which makes sense, given that it's an unreasonably large amount of data to introduce into the dataset, and this data that's produced by SMPL for the vertices isn't exactly trivial to find patterns in or use as predictors.

The R squared scores of the trials where ground truth values were included as dependent (y) values are noticeably lower than the scores of the ones where they are included as independent (X) values. This probably isn't a coincidence. While, at first, it may seem intuitive that including the ground truth values is a good idea, since they are meant to be used for measuring accuracy, the accuracy is hindered by the fact that it increases the number of features that need to be predicted by a significant amount. Given that predicting a larger number of feature values may lead to more discrepancies between the predicted values and the actual values, causing a lower R squared score, it is reasonable to assume that this is the cause for this pattern in the trials' accuracy results.